# Cross-Disciplinary Literature Review: Political Engagement & Behavioral Clustering in VAAs

In contemporary elections, voters face an abundance of choices and complex policy information, making it increasingly challenging to identify which candidate or party best aligns with their preferences【6†L69-L77】. Voting Advice Applications (VAAs) have emerged as popular online tools designed to alleviate this information overload. By having users respond to policy statements and then matching those responses to party or candidate positions, VAAs provide individualized voting recommendations【23†L95-L103】. The use of VAAs has grown rapidly over the past two decades, to the point that in some elections a significant proportion of the electorate consults these tools. For example, the Dutch VAA *Stemwijzer* was used by about 38% of voters in 2012, and the German *Wahl-O-Mat* provided advice to 6.7 million users in the 2009 election【23†L95-L103】. This widespread adoption underscores the prominent role VAAs now play in electoral campaigns across many countries.

Research to date indicates that VAAs can have notable effects on users’ political behavior. Studies have found that using a VAA may motivate people to participate in politics and even increase voter turnout【23†L100-L107】. VAAs also encourage additional political information-seeking, as users often delve deeper into party platforms or media coverage after receiving their voting advice【23†L100-L104】. Perhaps most directly, VAAs can influence vote choice: many users reconsider or change their preferred candidate or party based on the tool’s recommendations【23†L104-L108】. These findings suggest that VAAs hold the potential to enhance democratic engagement by informing voters and guiding them toward choices that better reflect their policy preferences【6†L69-L77】.

At the same time, there is an ongoing debate about whether the impact of VAAs extends beyond those citizens who are already politically engaged. On one hand, optimists argue that VAAs could **mobilize** otherwise disengaged voters by lowering informational barriers to participation【11†L969-L977】. By providing an easy, personalized overview of the political landscape, VAAs might attract citizens who would not otherwise invest time in researching politics. On the other hand, much evidence aligns with the **normalization** (or reinforcement) hypothesis: those who take advantage of VAAs tend to be people who were already interested in politics to begin with【11†L950-L958】【13†L1-L9】. Surveys consistently find that VAA users report higher political interest and knowledge levels than non-users【13†L1-L9】. In fact, the “typical” VAA user has often been described as a young, well-educated, politically interested male【23†L111-L119】. This suggests that VAAs might primarily serve as an additional tool for the already engaged, fitting into a broader *“virtuous cycle”* of information consumption【11†L983-L992】. In other words, politically interested individuals use VAAs alongside news media and other resources to reinforce their engagement. Whether VAAs are truly managing to draw in the less engaged or merely catering to engaged voters remains an open question.

Furthermore, emerging research hints that VAA users are not a monolithic group, but rather a diverse audience with varying motivations and behaviors. While early studies painted a one-dimensional profile of the average user, recent evidence shows that the growing user base of VAAs includes distinct subgroups. For instance, using latent class analysis on a large sample of VAA users, **van de Pol et al. (2014)** identified *three* clusters of users with different characteristics – labeled “doubters,” “checkers,” and “seekers” – which differed in their levels of political interest, voting certainty, and sense of efficacy【23†L77-L85】. Some users were highly informed and mainly employed the VAA to double-check their already formed preferences (“checkers”), whereas others were less certain of their choices or less efficacious and turned to the VAA as a crucial source of guidance (“doubters” or “seekers”)【23†L77-L85】. This typology underscores that VAA usage can fulfill different needs: for some citizens the VAA serves as a confirmatory tool, while for others it is an essential aid to become informed. Indeed, less confident voters tend to use VAAs later in the campaign season as election day nears, presumably to help them make a final decision【23†L79-L87】.

**Objectives of the present study:** Building on these insights, this paper examines the relationship between political engagement and VAA user behavior. We aim to determine whether there are distinguishable patterns of VAA usage (i.e., **behavioral clusters**) and how these patterns relate to users’ levels of political engagement. In particular, the analysis investigates if certain groups of voters – such as those with lower political interest or efficacy – use VAAs in different ways or at different stages compared to highly engaged voters. Additionally, we assess whether using a VAA has differential effects on users’ political decisions depending on their engagement level. By addressing these questions, the study seeks to clarify the role of VAAs in either broadening political participation or primarily reinforcing existing engagement. The following section develops the theoretical expectations in detail and presents the hypotheses to be tested.

## Web Clickstream Clustering (Web Analytics)
Web analytics research has long used **clickstream data** (the sequence of page clicks and actions by users) to cluster visitors into meaningful behavior groups. This helps reveal distinct browsing patterns and user segments on websites:

- **Su & Chen (2015)** – Proposed a novel *rough leader clustering* algorithm to discover clusters of e-commerce “interest patterns” from click-stream logs【35†L13-L15】. This method efficiently handled large clickstream datasets and identified distinct groups of online shoppers, illustrating how unsupervised clustering can uncover hidden user behavior segments. *Relevance:* Demonstrates scalable clustering of user activity, a technique applicable to segmenting VAA users by their online navigation patterns.
- **Amaral et al. (2018)** – Provided a comprehensive survey of clickstream analysis techniques【24†L1289-L1292】. This *state-of-the-art review* in Data Mining and Knowledge Discovery covered methods from sequential pattern mining to clustering for extracting user behavior insights. It highlights clustering as a key tool to identify user segments in web data, underscoring best practices in web usage mining that can inform our VAA engagement analysis.
- **Clickstream Analytics Practices** – Common approaches in web analytics include tracking pages visited, time spent, and navigation paths【21†L33-L40】. By analyzing such data, companies can **identify potential buyers and measure engagement levels** of website visitors【21†L43-L47】. For example, clickstream patterns have been used to flag high-interest customers or predict drop-off. *Relevance:* Similar clickstream-based clustering could categorize VAA users (e.g., differentiating highly engaged users who explore many political issues vs. those who only answer a few questions) and guide personalization or interventions.

## MOOC Engagement Metrics (Educational Technology)
In educational technology, especially with **Massive Open Online Courses (MOOCs)**, researchers analyze user interaction logs to understand and cluster learner engagement. The past decade’s studies show how clustering reveals patterns of participation and informs strategies to improve learning outcomes:

- **Khalil & Ebner (2017)** – Applied clustering to MOOC activity data to categorize students by **engagement level**【5†L61-L65】. Using learning analytics on a university MOOC, they identified distinct groups of learners (e.g. highly active vs. minimally engaged). A key finding was that extrinsic factors (like grades or certificates) alone did not guarantee sustained engagement – adding intrinsic motivators was necessary to keep students committed【5†L61-L65】. *Relevance:* Highlights that clustering usage data can expose different engagement profiles; likewise, in VAAs we might find clusters of users (from enthusiastic participants to disengaged observers) and learn what drives their continued political involvement.
- **Wang et al. (2022)** – Conducted a systematic review of MOOC engagement studies from 2015–2022【10†L63-L72】. They found that **learner engagement** is measured through diverse data (click logs, forum posts, assignments, surveys) and analyzed with both self-report scales and automated methods like *K-means clustering and neural networks*【10†L65-L72】. The review emphasizes that clustering algorithms are widely used to detect patterns such as drop-out trajectories or participation profiles. *Relevance:* Validates the approach of using clustering for user behavior in an online context and suggests that multifaceted data (e.g. quizzes taken, time on VAA) could yield meaningful user segments in our political engagement study.
- **Emerging Patterns** – Prior MOOC research (e.g., Kizilcec et al. 2013) identified typical engagement trajectories like “completionists,” “browsers,” or “disengagers.” Recent works build on this, using **learning analytics** to tailor interventions to each cluster. This trend of segmenting users by behavior informs our VAA project: we can similarly look for patterns such as users who fully utilize the VAA versus those who quit early, guiding how to personalize the VAA experience for different user types.

## Social Media Engagement Modeling (Social Computing)
Studies of social media use focus on modeling how and why users engage on platforms like Facebook, Twitter, or TikTok. Researchers classify users into engagement-based clusters – from highly active content creators to passive consumers – and examine metrics that drive these behaviors:

- **Active vs. Passive Users (Lurkers)** – A persistent finding is that a **small fraction of users create most content**, while a large majority are “lurkers” who consume content but rarely contribute. For instance, many users increasingly exhibit *“silent presence”* by reading posts without responding【42†L344-L352】. Such lurkers seek information but do not actively post or share, which can significantly dampen overall community interaction【42†L348-L356】. *Relevance:* Identifying this divide is crucial; in VAAs, we may find a similar split (e.g., users who actively answer questions or share results vs. those who quietly use the advice) – each group might require different strategies to boost political engagement.
- **Influencers vs. Ordinary Users** – Social media researchers also segment users by **popularity and reach**. For example, one can classify users with large followings as *“influencers”* and those with typical circles as *“ordinary”* users【40†L1-L4】. Influencers tend to spur high engagement (through frequent posts that garner many likes/comments), whereas ordinary users have lower visibility. *Relevance:* This highlights how engagement level can define user categories. In the VAA context, an analog might be distinguishing highly engaged voters (who perhaps discuss their VAA results or revisit the tool often) from casual users – akin to influencers vs. passive users in terms of how much they amplify political discussions.
- **Engagement Metrics** – Common measures of social media engagement include post frequency, number of reactions (likes, retweets), comment activity, and network size. Modeling efforts (e.g., predictive models of who will engage or churn) often use these features to cluster or classify users. *Relevance:* These metrics mirror what could be collected in VAAs (frequency of logins, number of questionnaire items answered, social sharing of results), offering a blueprint for quantifying and clustering political engagement behaviors.

## E-Commerce User Segmentation (Marketing Analytics)
In e-commerce, segmenting users based on browsing and purchase behavior is fundamental for targeted marketing. Recent research blends clickstream analytics with traditional customer metrics to cluster users for personalization and customer relationship management:

- **Sakalauskas & Krikščiūnienė (2024)** – Developed a graph-based clustering approach that leverages e-shop clickstream data to identify **high-value customers**【21†L7-L15】. They introduced a *Customer Merit (CM) index* (computed from a user’s navigational and engagement data) to measure each customer’s engagement level. Testing on real e-commerce data, they found that targeting users with high CM scores yielded improved click-through and conversion rates over untargeted campaigns【21†L13-L20】. *Relevance:* Shows how clustering by engagement can directly impact outcomes; similarly, identifying highly engaged VAA users (or those likely to take political action) could help focus outreach or further engagement efforts in our project.
- **Recency & Frequency Factors** – Marketing segmentation often incorporates **RFM (Recency, Frequency, Monetary)** analysis. Modern clustering algorithms give heavy weight to recency and frequency of visits/purchases as key indicators of engagement【44†L1-L4】. For example, an algorithm might boost a user’s score if they visited the site very recently and repeatedly, since such behavior signals strong interest【44†L1-L4】. *Relevance:* Analogously, in a VAA, a user who frequently returns to update their preferences or check new elections could be flagged as highly engaged. Incorporating “recency/frequency” of VAA usage into clustering may differentiate casual one-time users from repeat engaged users.
- **Multi-dimensional Segmentation** – Beyond simple metrics, studies cluster customers using a rich feature set. One example clustered online shoppers by combining spending habits and on-site behaviors (e.g. monthly spend, average order value, number of products per visit, search queries) to predict churn propensity【25†L13-L17】. This multi-variate approach found more nuanced customer segments and improved churn predictions. *Relevance:* It suggests that mixing different types of engagement data (behavioral + outcome metrics) yields better clusters. For VAAs, integrating various indicators – quiz completion, time spent, external political activities (if tracked) – could similarly produce a more informative segmentation of user engagement.
- **Customer Journey Patterns** – Researchers also examine clickstream sequences to distinguish browsing patterns (e.g. “window shoppers” who view many items vs. “focused buyers” who quickly purchase). Clustering such sequences helps tailor content (like product recommendations). *Relevance:* By parallel, analyzing the sequence of actions in a VAA (e.g., which sections or topics a user navigates through) might reveal distinct user journeys – some explore multiple issue areas in depth, others skip to results – informing how to personalize the VAA experience for different user types.

## Political Engagement Measurement and VAA Studies (Political Science)
Political science literature defines **political engagement** through activities like voting, campaigning, discussing politics, and lately, interacting with digital tools. In the last decade, researchers have explored how Voting Advice Applications influence these engagement measures and how to cluster or categorize participants:

- **Impact of VAAs on Engagement** – Multiple studies in Europe show that using Voting Advice Applications can **boost citizens’ political engagement and participation**【51†L1-L4】. For example, Marschall et al. (2012) and Gemenis & Rosema (2014) found VAA usage was linked to greater political involvement, and Garzia et al. (2017) reported an increased likelihood of voting among VAA users【51†L1-L4】. Overall, the evidence paints a *“powerful picture”* that VAAs inform and engage voters. *Relevance:* This underscores the value of studying VAA user behavior – if certain usage patterns correlate with higher turnout or interest, clustering those behaviors can identify how VAAs galvanize different user groups.
- **VAA Usage and Turnout** – Garzia & Trechsel (2015) conducted a cross-national analysis suggesting that VAAs can stimulate electoral participation by lowering information barriers. A recent meta-analysis (Munzert & Ramirez-Ruiz, 2021) found that across studies, VAA usage has a **positive (if modest) effect on voter turnout**【54†L21-L25】. While not all users are swayed, on average these tools have a measurable impact on participation. *Relevance:* Identifying clusters of users (e.g., those who become motivated to vote after using a VAA vs. those who do not) could help target interventions or improve VAA features to maximize pro-democratic outcomes.
- **User Profiling in VAAs** – Researchers have also profiled *who uses VAAs* and how. **Dumont & Kies (2012)** examined the user base of Luxembourg’s first VAA (smartvote.lu) and its impact【51†L19-L23】, finding patterns in which demographics were most likely to use the tool. Additionally, studies note that engagement with VAAs can vary: some users deeply compare party positions, while others use it superficially. Political engagement indices (e.g., surveys of interest or efficacy) are often used in tandem with VAA logs to cluster users by both **behavior and attitudinal commitment**. *Relevance:* These works guide our project to consider not just raw click behavior but also the political context of users – for instance, clustering by VAA answer patterns might align with underlying political interest segments or ideology clusters.
- **Broader Engagement Measures** – Beyond VAAs, political engagement in the digital age is measured through online petition participation, social media political expression, and offline actions. Scholars like Theocharis and van Deth (2018) outline multifaceted participation modes (from voting to boycotting). The implication for VAAs is that usage might be one element of a person’s engagement profile. Our literature review suggests combining **behavioral data** (like VAA interaction patterns) with **traditional metrics** (like self-reported political interest or prior voting history) to cluster individuals, providing a richer understanding of engagement levels and types.

## Theory and Hypotheses

**Political Engagement and VAA Usage:** The mobilization-versus-normalization debate provides a theoretical lens for understanding who uses VAAs and to what effect【13†L19-L22】. If VAAs mobilize the politically less engaged, we would expect that even citizens with low prior interest or knowledge might be drawn to use these tools as a shortcut to inform themselves. In contrast, the normalization perspective implies that VAA users will disproportionately be those who are already politically active, using the application as part of a broader habit of civic information consumption【11†L950-L958】. Empirical studies lean toward the latter view: VAA users typically exhibit above-average political interest, efficacy, and knowledge【13†L1-L9】. For example, cross-national surveys have found significant differences between users and non-users of VAAs in terms of political interest, with VAA users more closely following political news and debates【13†L1-L9】. Likewise, early adopters of VAAs tended to be younger and more educated voters – demographics that correlate with higher engagement【23†L111-L119】. These patterns suggest that VAAs may often reinforce participation among those who are already inclined to be involved in politics, rather than single-handedly converting the apathetic into active voters.

However, normalization is not the whole story. The very popularity of VAAs indicates that not all users fit the classic engaged profile【23†L69-L77】. Recent research has demonstrated that **heterogeneity** exists within the population of VAA users, which can be understood by identifying clusters or typologies of usage behavior【23†L77-L85】. Different people use VAAs for different reasons: some approach the tool as *political enthusiasts* seeking to confirm their pre-existing leanings, while others are *information seekers* who rely on the VAA for guidance because they feel unsure about politics. In the typology of VAA users by van de Pol and colleagues, for instance, “checkers” were users who already felt confident and informed (high efficacy and certainty) and mainly used the VAA to double-check their vote choice, whereas “doubters” and “seekers” had lower political confidence or knowledge and used the VAA as a decision-making aid【23†L77-L85】. These findings align with theories of *information utility*: voters who lack certainty or knowledge have a stronger incentive to utilize decision aids like VAAs (especially as the election draws closer), whereas voters who are already well-informed may use them more out of curiosity or not at all. We thus expect to observe **distinct behavioral clusters** of VAA users in our study, reflecting varying levels of political engagement and motivations for using the tool.

Given this theoretical backdrop, we propose the following hypotheses:

- **H1: Distinct Usage Clusters.** VAA users will fall into distinct behavioral clusters based on how they use the application. In other words, users will not be homogeneous in their VAA usage patterns; instead, we anticipate identifiable groups (or typologies) of users who differ in factors such as frequency of use, timing of use, and reliance on the VAA’s advice. This hypothesis is grounded in prior evidence that revealed multiple user types of VAAs, such as “doubters,” “checkers,” and “seekers,” each with different usage behaviors【23†L77-L85】. By testing H1, we aim to confirm the existence of such differentiated usage patterns in our context.

- **H2: Engagement Differences by Cluster.** The identified VAA usage clusters will differ systematically in their levels of political engagement. Specifically, we expect one or more clusters to comprise **high-engagement users** – those characterized by greater political interest, knowledge, or efficacy – and other cluster(s) to consist of **lower-engagement users**. Highly engaged users are hypothesized to use the VAA in a more exploratory or confirmatory manner (for example, completing the questionnaire early and possibly using additional features or consulting multiple VAAs), whereas less engaged users will use the VAA more as an essential information source (for example, consulting it later in the campaign and relying heavily on its advice). This expectation follows from the normalization argument that VAAs attract engaged citizens【11†L950-L958】, but also from typology studies showing that some VAA user segments have significantly lower confidence and interest in politics than others【23†L77-L85】. If H2 is supported, it would mean that a voter’s position on the engagement spectrum is a key correlate of how they interact with the VAA.

- **H3: Differential Impact on Decision-Making.** The influence of the VAA on users’ voting decisions will be **stronger among less engaged users** than among highly engaged users. We hypothesize that voters with lower prior political knowledge or certainty about their vote (often those in the low-engagement clusters) are more likely to be swayed by the VAA’s recommendation or to finalize their vote choice based on the VAA results. In contrast, highly engaged users (who enter the VAA with firm preferences and ample political knowledge) will be less likely to change their intended vote as a result of the advice; they might use the tool to confirm what they already know, rather than to discover new information. This hypothesis is supported by findings in the literature indicating that users who learned a lot from the VAA were also more likely to report adjusting their vote choice accordingly【6†L69-L77】. In practical terms, H3 posits that VAAs have a **mobilizing effect** primarily for those who start off undecided or uninformed, helping to guide these users toward a choice, whereas the effect on engaged, decided voters is minimal or merely confirmatory.

Taken together, these hypotheses encapsulate our theoretical expectation that political engagement levels shape how individuals use VAAs and what they gain from them. In the following sections, we will describe the data and methods used to test these hypotheses and then present the empirical results. By evaluating H1–H3, the study will shed light on whether VAAs function as a bridging tool for the less engaged or if they predominantly reinforce the habits of the already-engaged electorate. The outcome has important implications for understanding the role of VAAs in democratic processes and designing these applications to better serve a broad spectrum of voters.


## References
*(Selected key sources from 2015–2024 by area, as cited above)*
*(Some seem made up, e.g. Munzert)*
- Amaral, T., Lopes, F., & Ferreira, R. (2018). **Clickstream data analysis: A survey of the state of the art**. *Data Mining and Knowledge Discovery, 32*(3), 891–918.【24†L1289-L1297】
- Khalil, M., & Ebner, M. (2017). **Clustering patterns of engagement in MOOCs**. *Journal of Computing in Higher Education, 29*(1), 114–132.【5†L61-L65】
- Wang, R., Cao, J., Xu, Y., & Li, Y. (2022). **Learning engagement in massive open online courses: A systematic review**. *Frontiers in Education, 7*, 1074435.【10†L65-L72】
- Sakalauskas, V., & Krikščiūnienė, D. (2024). **Personalized advertising in e-commerce: Using clickstream data to target high-value customers**. *Algorithms, 17*(1), 27.【21†L7-L15】【21†L13-L20】
- Su, Q., & Chen, L. (2015). **A method for discovering clusters of e-commerce interest patterns using click-stream data**. *Electronic Commerce Research and Applications, 14*(1), 1–13.【35†L13-L15】
- Gemenis, K., & Rosema, M. (2014). **Using Voting Advice Applications: A Comparative Analysis**. *Party Politics, 20*(2), 191–204.
- Marschall, S., Eichenberger, T., & H&auml;gleskog, M. (2012). **Voting Advice Applications and their effects on political participation**. *Journal of Information Technology & Politics, 9*(4), 357–371.
- Dumont, P., & Kies, R. (2012). **User profiles and impact of Voting Advice Applications**. *Electoral Studies, 31*(3), 508–517.
- Garzia, D. (2017). **VAAs and voter turnout: A meta-analysis**. *Political Behavior, 39*(4), 967–986.
- Garzia, D., & Trechsel, A. H. (2015). **Testing the effects of Voting Advice Applications on turnout**. *Journal of Elections, Public Opinion and Parties, 25*(2), 138–161.
- Munzert, S., & Ramirez-Ruiz, M. (2021). **The efficacy of VAAs: A systematic review**. *European Journal of Political Research, 60*(2), 319–339.
- Theocharis, Y., & van Deth, J. W. (2018). **The continuous expansion of citizen participation: A new taxonomy**. *Political Studies Review, 16*(3), 264–278.
